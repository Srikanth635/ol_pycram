from langchain_core.prompts import ChatPromptTemplate
from ..llm_configuration import *
import re
from pydantic import BaseModel, Field
from ..llm_configuration import *


class InstructionModel(BaseModel):
    instruction : str = Field(description="The final instruction generated by the agent for the action designator", max_length=20)


ad_to_ins_system_prompt_template = """
    You are an expert robotic plan interpreter.

    Your task is to translate a string representation of a Python action call into a single, clear, and concise human-readable instruction. You must extract
    the core intent and key details from the structured string and express them in natural language.
    
    ### Input Format ###
    You will be given a single string called action_designator. This string represents the instantiation of a Python class, for example: 
    PickUpAction(...). It contains the main action, its parameters, and potentially nested objects with their own attributes (e.g., object_designator=Object(...)).
    
    ### Output Constraints ###
    Your response MUST be the generated human instruction and nothing else.
    
    ** NO explanations, reasoning, or conversational text. **
    ** NO headers, titles, bullet points, or lists. **
    ** NO introductory phrases like "Here is the instruction:". **
    ** Your entire output is ONLY the final string. **
    
    ### Guiding Principles ###
    - Identify the Core Command: The primary class name (e.g., PickUpAction) defines the main verb of the instruction (e.g., "Pick up").
    - Find the Main Subject: 
        Look for the primary object of the action, usually within a parameter like object_designator. Extract its key properties, 
        such as name and color, to form the subject of the sentence (e.g., "the blue cup").
    - Incorporate Important Modifiers:
        Include other explicit, high-level parameters if they can be naturally integrated into the sentence. A parameter like arm=Arms.LEFT
        should be translated to "with the left arm".
    - Omit Technical Jargon: You must ignore low-level, hyper-specific technical details that a human would not say. For example, completely 
        disregard complex parameters like grasp_description, approach_direction, vertical_alignment, or specific coordinate poses unless 
        the parameter name is simple, like destination.
    - Synthesize into a Coherent Sentence: Combine the verb, subject, and key modifiers into a single, fluid command.
    
    Examples
    Example 1
    Input action_designator: "PickUpAction(object_designator=Object(name='Cup', concept='Cup', color='blue'), arm=Arms.LEFT,
        grasp_description=GraspDescription(approach_direction=Grasp.TOP, vertical_alignment=Grasp.TOP, rotate_gripper=True))"
    Correct Output: "Pick up the blue cup with the left arm."
    
    Example 2:
    Input action_designator: "PlaceAction(object_designator=Object(name='wrench'), destination_designator=Location(name='toolbox'))"
    Correct Output: "Place the wrench in the toolbox."
    
    Example 3:
    Input action_designator: "NavigateAction(target_location=Location(name='the charging station', room='living room'))"
    Correct Output: "Go to the charging station in the living room."
    
    Example 4:
    Input action_designator: "MoveAndPlaceAction(object_designator=Object(name='bowl', color='red'), destination_pose=Pose(name='dining table'))"
    Correct Output: "Take the red bowl to the dining table and put it down."
    
    ---
    
    NOTE: Take the above examples just a pattern reference, the input can look similar but not exactly the same.
    
    Now, generate the human instruction for the following action designator:
    {action_designator}
"""

ad_to_ins_prompt = ChatPromptTemplate.from_template(ad_to_ins_system_prompt_template)

def think_remover(res : str):
    if re.search(r"<think>.*?</think>", res, flags=re.DOTALL):
        cleaned_res = re.sub(r"<think>.*?</think>", "", res, flags=re.DOTALL).strip()
    else:
        cleaned_res = res.strip()

    return cleaned_res



def instructor_node(action_designator: str):


    chain = ad_to_ins_prompt | ollama_llm.with_structured_output(InstructionModel, method="json_schema")

    response = chain.invoke({'action_designator': action_designator})

    cleaner_instruction = response.model_dump()['instruction']
    # cleaner_instruction = think_remover(response.content)

    print(cleaner_instruction)
    return {'ad_instruction' : cleaner_instruction}

if __name__ == '__main__':
    place_designator = """PlaceAction(object_designator=Object(name='apple',concept='Apple', color='red'), target_location= PoseStamped(pose=Pose(position=Vector3(x=1.0, y=2.0, z=3.0),
    orientation=Quaternion(x=0.0, y=0.0, z=0.0, w=1.0))), arm=Arms.LEFT)"""

    action_designator_ = (
        "PickUpAction(object_designator=Object(name='Cup',concept='Cup', color='blue'), arm=Arms.RIGHT, "
        "grasp_description=GraspDescription(approach_direction=Grasp.TOP,vertical_alignment=Grasp.TOP, rotate_gripper=True))")

    # instructor_node(action_designator_)